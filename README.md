# Detector de Fake News com Machine Learning ğŸ•µï¸â€â™‚ï¸

Projeto final desenvolvido para a disciplina de **InteligÃªncia Artificial**. O objetivo Ã© classificar notÃ­cias em "Reais" ou "Fakes" utilizando Processamento de Linguagem Natural (NLP) e RegressÃ£o LogÃ­stica, com foco em interpretabilidade e eliminaÃ§Ã£o de viÃ©s.

---

## ğŸ“Š Sobre o Dataset (Abordagem HÃ­brida)
Inicialmente, enfrentamos problemas de *overfitting* temporal (o modelo "decorou" o cenÃ¡rio polÃ­tico de 2018). Para corrigir isso e garantir generalizaÃ§Ã£o, utilizamos uma abordagem de **Data Augmentation** combinando dois datasets distintos:

1. **Fake.br-Corpus**
2. **FakeTrue.br**

Isso resultou em um **"Super Dataset" Balanceado** com **10.782 notÃ­cias**, rigorosamente dividido em:
* ğŸŸ¢ **50% NotÃ­cias Reais**
* ğŸ”´ **50% NotÃ­cias Falsas**

---

## ğŸ› ï¸ Tecnologias e Metodologia Utilizadas no Projeto

### ğŸ› ï¸ Tecnologias 
* **Python 3.13.7**
* **Pandas:** ManipulaÃ§Ã£o de dados.
* **Scikit-Learn:** Machine Learning (RegressÃ£o LogÃ­stica).
* **TF-IDF:** VetorizaÃ§Ã£o de texto.
* **NLTK:** Processamento de texto e stopwords.
* **Streamlit:** 

### ğŸ› ï¸ Metodologias 
* **Modelo:** RegressÃ£o LogÃ­stica (*Logistic Regression*). Escolhido por ser um modelo "White Box" (transparente), permitindo auditoria de pesos e correÃ§Ã£o de vieses.
* **VetorizaÃ§Ã£o:** TF-IDF (Term Frequency-Inverse Document Frequency).
* **Split de Treino/Teste:** 70% para Treino e 30% para ValidaÃ§Ã£o (com estratificaÃ§Ã£o).
* **LÃ³gica de Incerteza:** ImplementaÃ§Ã£o de uma "Zona de DÃºvida". Se a confianÃ§a da IA ficar entre 45% e 55%, o sistema retorna **"Inconclusivo"** para evitar alucinaÃ§Ãµes em temas desconhecidos.
* **CorreÃ§Ã£o de ViÃ©s:** O modelo foi ajustado com `fit_intercept=False` para eliminar o preconceito estatÃ­stico inicial.

---

## ğŸ“‚ Estrutura do Projeto

'''text
ia/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Datasets originais (.csv)
â”‚   â”œâ”€â”€ processed/      # Dataset unificado e limpo
â”‚   â”œâ”€â”€ models/         # Modelo treinado (.pkl) e vetorizador
â”‚   â””â”€â”€ matriz_confusao.png # GrÃ¡fico de performance final
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ analise_inicial.py # DiagnÃ³stico inicial dos dados brutos
â”‚   â”œâ”€â”€ app.py             # AplicaÃ§Ã£o Web (Frontend com Streamlit)
â”‚   â”œâ”€â”€ auditoria.py       # ValidaÃ§Ã£o de amostras aleatÃ³rias (Sanity Check)
â”‚   â”œâ”€â”€ data_cleaning.py   # Script de limpeza e unificaÃ§Ã£o dos datasets
â”‚   â”œâ”€â”€ gerar_grafico.py   # Gera a visualizaÃ§Ã£o da Matriz de ConfusÃ£o
â”‚   â”œâ”€â”€ teste_manual.py    # Teste via terminal (sem interface grÃ¡fica)
â”‚   â”œâ”€â”€ train_model.py     # Script de treinamento da IA (Treino/Teste split)
â”‚   â””â”€â”€ ver_pesos.py       # DiagnÃ³stico de viÃ©s (pesos das palavras)
â”œâ”€â”€ README.md              # DocumentaÃ§Ã£o do projeto
â””â”€â”€ requirements.txt       # Lista de dependÃªncias
'''

---

## ğŸš€ Como Rodar o Projeto

1. **Instale as dependÃªncias:**
Certifique-se de ter o Python instalado e, no terminal, com a pasta do projeto selecionada, rode:

   ```bash
   pip install -r requirements.txt
   ```

Ou instale manualmente:

   ```bash
   pip install pandas numpy scikit-learn nltk matplotlib seaborn jupyter streamlit
   ```

2. **PreparaÃ§Ã£o (Opcional - JÃ¡ realizado)**
Os scripts de limpeza e treinamento (data_cleaning.py e train_model.py) jÃ¡ foram executados e os modelos estÃ£o salvos na pasta data/models. NÃ£o Ã© necessÃ¡rio rodÃ¡-los novamente para testar.

3. **Executando a AplicaÃ§Ã£o Web**
Para abrir a interface visual e testar notÃ­cias em tempo real:

   ```bash
   streamlit run src/app.py
   ```
O navegador abrirÃ¡ automaticamente com o sistema pronto para uso.

## ğŸ“ˆ Resultados AlcanÃ§ados

O modelo final atingiu uma performance robusta no conjunto de teste (3.235 notÃ­cias nunca vistas pelo modelo):

* **MÃ©trica**                    **Resultado**
* **AcurÃ¡cia Global:**           91.53%
* **PrecisÃ£o (NotÃ­cias Reais):** 97%
* **PrecisÃ£o (Fake News):**      86%

Nota: O modelo prioriza a cautela. A taxa de falsos positivos (acusar uma verdade de ser mentira) foi reduzida a apenas ~2%, garantindo confiabilidade.